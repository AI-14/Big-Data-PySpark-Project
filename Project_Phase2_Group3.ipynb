{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction**\n",
    "In this notebook, we will execute phase2 of the ICS474 project. \n",
    "\n",
    "### **Table of Contents**\n",
    "- Finding a \"Big Dataset\" - 1.14GB - ADULTS DATASET.\n",
    "- Detailed description of the dataset.\n",
    "- Importing libraries and setting up PySpark.\n",
    "- Preprocessing the dataset.\n",
    "   - 4.1 Exploring the data.\n",
    "   - 4.2 Preprocessing for classification task.\n",
    "   - 4.3 Preprocessing for regression task. \n",
    "- Splitting the data into training and testing.\n",
    "- Building a classification & a regression model and testing/reporting the results.\n",
    "  - Classification task.\n",
    "  - Regression task.\n",
    "- Using the models.\n",
    "  - Classification prediction.\n",
    "  - Regression prediction.\n",
    "\n",
    "<br></br>\n",
    "Team members (Group3):\n",
    " - Amaan Izhar (201781130/Section02)\n",
    " - Farhan M. Abdul Qadir (201771950/Section02)\n",
    " - AbdulJawad Mohammad (201744310/Section03) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Finding a \"Big Dataset\" - 1.14GB - ADULTS DATASET.**\n",
    "We found the dataset on Kaggle. Its size is 1.14GB. \n",
    "\n",
    "Link: https://www.kaggle.com/brijeshbmehta/adult-datasets?select=adult10m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Detailed description of the dataset.**\n",
    "   - Dataset Task: Predict whether the income of each adult exceeds $50K per year based on census data.\n",
    "   - List of Attributes:\n",
    "       1. Continuous Features:\n",
    "           - <b>age</b>\n",
    "           - <b>fnlwgt(Final Weight)</b>\n",
    "           - <b>education-num</b>\n",
    "           - <b>capital-gain</b>\n",
    "           - <b>capital-loss</b>\n",
    "           - <b>hourse-per-week</b>\n",
    "       2. Categorical Features:\n",
    "           - <b>workclass</b>: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "fnlwgt: continuous\n",
    "           - <b>education</b>: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool\n",
    "           - <b>marital-status</b>: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "           - <b>occupation</b>: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "           - <b>relationship</b>: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried\n",
    "           - <b>race</b>: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black\n",
    "           - <b>sex</b>: Female, Male\n",
    "           - <b>native-country</b>: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands\n",
    "           - <b>SalaryClass</b>: <=50k OR >50k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing libraries and setting up PySpark.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark dependency found -> C:\\Spark\\spark-3.0.3-bin-hadoop2.7\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "print(f'Spark dependency found -> {findspark.find()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col, countDistinct\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder, StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up spark.\n",
    "spark = SparkSession.builder.appName('ICS474Project').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocessing the dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(path='adult10m', sep=',', inferSchema=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+------+---------+---+------------------+-----------------+-------------+-----+------+----+---+---+-------------+-----------+\n",
      "|a  |wc              |fw    |ed       |edN|ms                |oc               |rel          |race |sex   |cg  |cl |hpw|nc           |salaryClass|\n",
      "+---+----------------+------+---------+---+------------------+-----------------+-------------+-----+------+----+---+---+-------------+-----------+\n",
      "|39 |State-gov       |77516 |Bachelors|13 |Never-married     |Adm-clerical     |Not-in-family|White|Male  |2174|0  |40 |United-States|<=50K      |\n",
      "|50 |Self-emp-not-inc|83311 |Bachelors|13 |Married-civ-spouse|Exec-managerial  |Husband      |White|Male  |0   |0  |13 |United-States|<=50K      |\n",
      "|38 |Private         |215646|HS-grad  |9  |Divorced          |Handlers-cleaners|Not-in-family|White|Male  |0   |0  |40 |United-States|<=50K      |\n",
      "|53 |Private         |234721|11th     |7  |Married-civ-spouse|Handlers-cleaners|Husband      |Black|Male  |0   |0  |40 |United-States|<=50K      |\n",
      "|28 |Private         |338409|Bachelors|13 |Married-civ-spouse|Prof-specialty   |Wife         |Black|Female|0   |0  |40 |Cuba         |<=50K      |\n",
      "+---+----------------+------+---------+---+------------------+-----------------+-------------+-----+------+----+---+---+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = ['a', 'wc', 'fw', 'ed', 'edN', \n",
    "           'ms', 'oc', 'rel', 'race', 'sex', \n",
    "           'cg', 'cl', 'hpw', 'nc', 'salaryClass']\n",
    "\n",
    "df = df.toDF(*columns)\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape = 10000000, 15\n"
     ]
    }
   ],
   "source": [
    "print(f'df shape = {df.count()}, {len(df.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+---+----+---+---+---+---+---+-----------+\n",
      "|  a| wc| fw| ed|edN| ms| oc|rel|race|sex| cg| cl|hpw| nc|salaryClass|\n",
      "+---+---+---+---+---+---+---+---+----+---+---+---+---+---+-----------+\n",
      "|  0|  0|  0|  0|  0|  0|  0|  0|   0|  0|  0|  0|  0|  0|          0|\n",
      "+---+---+---+---+---+---+---+---+----+---+---+---+---+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+---+---+----+-----+-----+---+-------------+\n",
      "| as|wcs|edNs|mss|ocs|rels|races|sexes|ncs|salaryClasses|\n",
      "+---+---+----+---+---+----+-----+-----+---+-------------+\n",
      "| 73|  9|  16|  7| 15|   6|    5|    2| 42|            2|\n",
      "+---+---+----+---+---+----+-----+-----+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(countDistinct(\"a\").alias(\"as\"),\n",
    "          countDistinct(\"wc\").alias(\"wcs\"), \n",
    "          countDistinct('edN').alias(\"edNs\"), \n",
    "          countDistinct('ms').alias(\"mss\"),\n",
    "          countDistinct('oc').alias(\"ocs\"),\n",
    "          countDistinct('rel').alias(\"rels\"), \n",
    "          countDistinct('race').alias(\"races\"), \n",
    "          countDistinct('sex').alias(\"sexes\"), \n",
    "          countDistinct('nc').alias(\"ncs\"), \n",
    "          countDistinct('salaryClass').alias(\"salaryClasses\")\n",
    "          ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+\n",
      "|              wc|  count|\n",
      "+----------------+-------+\n",
      "|Self-emp-not-inc|1110296|\n",
      "|       Local-gov|1110045|\n",
      "|       State-gov|1108295|\n",
      "|         Private|1129254|\n",
      "|     Without-pay|1106759|\n",
      "|     Federal-gov|1108964|\n",
      "|    Never-worked|1106779|\n",
      "|               ?|1110548|\n",
      "|    Self-emp-inc|1109060|\n",
      "+----------------+-------+\n",
      "\n",
      "+---+------+\n",
      "|edN| count|\n",
      "+---+------+\n",
      "|  7|623919|\n",
      "| 15|624516|\n",
      "| 11|624818|\n",
      "|  3|621756|\n",
      "|  8|623454|\n",
      "| 16|623397|\n",
      "|  5|623844|\n",
      "|  6|623061|\n",
      "|  9|633268|\n",
      "|  1|622270|\n",
      "| 10|630730|\n",
      "|  4|623699|\n",
      "| 12|623620|\n",
      "| 13|629065|\n",
      "| 14|624905|\n",
      "|  2|623678|\n",
      "+---+------+\n",
      "\n",
      "+--------------------+-------+\n",
      "|                  ms|  count|\n",
      "+--------------------+-------+\n",
      "|           Separated|1423556|\n",
      "|       Never-married|1433420|\n",
      "|Married-spouse-ab...|1426068|\n",
      "|            Divorced|1428751|\n",
      "|             Widowed|1426311|\n",
      "|   Married-AF-spouse|1423834|\n",
      "|  Married-civ-spouse|1438060|\n",
      "+--------------------+-------+\n",
      "\n",
      "+-----------------+------+\n",
      "|               oc| count|\n",
      "+-----------------+------+\n",
      "|            Sales|669391|\n",
      "|  Exec-managerial|668120|\n",
      "|   Prof-specialty|667983|\n",
      "|Handlers-cleaners|666092|\n",
      "|  Farming-fishing|665458|\n",
      "|     Craft-repair|668845|\n",
      "| Transport-moving|665755|\n",
      "|  Priv-house-serv|666141|\n",
      "|  Protective-serv|665134|\n",
      "|    Other-service|667307|\n",
      "|     Tech-support|666043|\n",
      "|Machine-op-inspct|666409|\n",
      "|     Armed-Forces|664604|\n",
      "|                ?|664720|\n",
      "|     Adm-clerical|667998|\n",
      "+-----------------+------+\n",
      "\n",
      "+--------------+-------+\n",
      "|           rel|  count|\n",
      "+--------------+-------+\n",
      "|     Own-child|1665327|\n",
      "| Not-in-family|1667966|\n",
      "|     Unmarried|1665499|\n",
      "|          Wife|1662874|\n",
      "|Other-relative|1661347|\n",
      "|       Husband|1676987|\n",
      "+--------------+-------+\n",
      "\n",
      "+------------------+-------+\n",
      "|              race|  count|\n",
      "+------------------+-------+\n",
      "|             Other|1993199|\n",
      "|Amer-Indian-Eskimo|1992804|\n",
      "|             White|2022489|\n",
      "|Asian-Pac-Islander|1993385|\n",
      "|             Black|1998123|\n",
      "+------------------+-------+\n",
      "\n",
      "+------+-------+\n",
      "|   sex|  count|\n",
      "+------+-------+\n",
      "|Female|4993804|\n",
      "|  Male|5006196|\n",
      "+------+-------+\n",
      "\n",
      "+------------------+------+\n",
      "|                nc| count|\n",
      "+------------------+------+\n",
      "|       Philippines|237818|\n",
      "|           Germany|237207|\n",
      "|          Cambodia|236855|\n",
      "|            France|237060|\n",
      "|            Greece|238126|\n",
      "|            Taiwan|237352|\n",
      "|           Ecuador|237848|\n",
      "|         Nicaragua|237367|\n",
      "|              Hong|237020|\n",
      "|              Peru|237345|\n",
      "|             India|237656|\n",
      "|             China|236381|\n",
      "|             Italy|237344|\n",
      "|Holand-Netherlands|238206|\n",
      "|              Cuba|237847|\n",
      "|             South|237356|\n",
      "|              Iran|237379|\n",
      "|           Ireland|236718|\n",
      "|          Thailand|237744|\n",
      "|              Laos|236585|\n",
      "|       El-Salvador|237399|\n",
      "|            Mexico|238131|\n",
      "|         Guatemala|237229|\n",
      "|          Honduras|236848|\n",
      "|        Yugoslavia|238139|\n",
      "|       Puerto-Rico|237139|\n",
      "|           Jamaica|238136|\n",
      "|            Canada|237356|\n",
      "|     United-States|266065|\n",
      "|Dominican-Republic|238174|\n",
      "+------------------+------+\n",
      "only showing top 30 rows\n",
      "\n",
      "+-----------+-------+\n",
      "|salaryClass|  count|\n",
      "+-----------+-------+\n",
      "|      <=50K|5006729|\n",
      "|       >50K|4993271|\n",
      "+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df['wc']).count().show()\n",
    "df.groupBy(df['edN']).count().show()\n",
    "df.groupBy(df['ms']).count().show()\n",
    "df.groupBy(df['oc']).count().show()\n",
    "df.groupBy(df['rel']).count().show()\n",
    "df.groupBy(df['race']).count().show()\n",
    "df.groupBy(df['sex']).count().show()\n",
    "df.groupBy(df['nc']).count().show(30)\n",
    "df.groupBy(df['salaryClass']).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+---+----+----------------+---+-----------------+-----------+\n",
      "|   a|      fw|    cg| cl| hpw|              wc|edN|               oc|salaryClass|\n",
      "+----+--------+------+---+----+----------------+---+-----------------+-----------+\n",
      "|39.0| 77516.0|2174.0|0.0|40.0|       State-gov| 13|     Adm-clerical|      <=50K|\n",
      "|50.0| 83311.0|   0.0|0.0|13.0|Self-emp-not-inc| 13|  Exec-managerial|      <=50K|\n",
      "|38.0|215646.0|   0.0|0.0|40.0|         Private|  9|Handlers-cleaners|      <=50K|\n",
      "|53.0|234721.0|   0.0|0.0|40.0|         Private|  7|Handlers-cleaners|      <=50K|\n",
      "|28.0|338409.0|   0.0|0.0|40.0|         Private| 13|   Prof-specialty|      <=50K|\n",
      "+----+--------+------+---+----+----------------+---+-----------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new = df.select(col('a').cast('double'), col('fw').cast('double'), \n",
    "                      col('cg').cast('double'), col('cl').cast('double'),\n",
    "                      col('hpw').cast('double'), 'wc', 'edN', 'oc', 'salaryClass')\n",
    "df_new.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing for classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+---+----+-----+------+-----+--------------+\n",
      "|   a|      fw|    cg| cl| hpw|wc_si|edN_si|oc_si|salaryClass_si|\n",
      "+----+--------+------+---+----+-----+------+-----+--------------+\n",
      "|39.0| 77516.0|2174.0|0.0|40.0|  6.0|   2.0|  3.0|           0.0|\n",
      "|50.0| 83311.0|   0.0|0.0|13.0|  2.0|   2.0|  2.0|           0.0|\n",
      "|38.0|215646.0|   0.0|0.0|40.0|  0.0|   0.0|  8.0|           0.0|\n",
      "|53.0|234721.0|   0.0|0.0|40.0|  0.0|   6.0|  8.0|           0.0|\n",
      "|28.0|338409.0|   0.0|0.0|40.0|  0.0|   2.0|  4.0|           0.0|\n",
      "+----+--------+------+---+----+-----+------+-----+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Indexing categorical features.\n",
    "indexer = StringIndexer(inputCols=['wc', 'edN', 'oc', 'salaryClass'], outputCols=['wc_si', 'edN_si', 'oc_si', 'salaryClass_si']) \n",
    "df_indexed = indexer.fit(df_new).transform(df_new) \n",
    "df_indexed = df_indexed.drop(*['wc', 'edN', 'oc', 'salaryClass'])\n",
    "df_indexed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+---+----+-----+------+-----+--------------+-------------+--------------+--------------+\n",
      "|a   |fw      |cg    |cl |hpw |wc_si|edN_si|oc_si|salaryClass_si|wc_ohe       |edN_ohe       |oc_ohe        |\n",
      "+----+--------+------+---+----+-----+------+-----+--------------+-------------+--------------+--------------+\n",
      "|39.0|77516.0 |2174.0|0.0|40.0|6.0  |2.0   |3.0  |0.0           |(8,[6],[1.0])|(15,[2],[1.0])|(14,[3],[1.0])|\n",
      "|50.0|83311.0 |0.0   |0.0|13.0|2.0  |2.0   |2.0  |0.0           |(8,[2],[1.0])|(15,[2],[1.0])|(14,[2],[1.0])|\n",
      "|38.0|215646.0|0.0   |0.0|40.0|0.0  |0.0   |8.0  |0.0           |(8,[0],[1.0])|(15,[0],[1.0])|(14,[8],[1.0])|\n",
      "|53.0|234721.0|0.0   |0.0|40.0|0.0  |6.0   |8.0  |0.0           |(8,[0],[1.0])|(15,[6],[1.0])|(14,[8],[1.0])|\n",
      "|28.0|338409.0|0.0   |0.0|40.0|0.0  |2.0   |4.0  |0.0           |(8,[0],[1.0])|(15,[2],[1.0])|(14,[4],[1.0])|\n",
      "+----+--------+------+---+----+-----+------+-----+--------------+-------------+--------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding the categorical features.\n",
    "onehot = OneHotEncoder(inputCols=['wc_si', 'edN_si', 'oc_si'], outputCols=['wc_ohe', 'edN_ohe', 'oc_ohe'])\n",
    "df_ohe = onehot.fit(df_indexed).transform(df_indexed)\n",
    "df_ohe.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['a', 'fw', 'cg', 'cl', 'hpw']:\n",
    "    assembler = VectorAssembler(inputCols=[col], outputCol=f'{col}_vec')\n",
    "    df_ohe = assembler.transform(df_ohe)\n",
    "\n",
    "    scaler = StandardScaler(inputCol=f'{col}_vec', outputCol=f'{col}_sc')\n",
    "    df_ohe = scaler.fit(df_ohe).transform(df_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------------------+-----+--------------------+-------------+--------------+--------------+-----+\n",
      "|a_sc                |fw_sc               |cg_sc                |cl_sc|hpw_sc              |wc_ohe       |edN_ohe       |oc_ohe        |label|\n",
      "+--------------------+--------------------+---------------------+-----+--------------------+-------------+--------------+--------------+-----+\n",
      "|[1.8487061379573442]|[0.6877735810696858]|[0.19880196875001743]|[0.0]|[1.407781753443814] |(8,[6],[1.0])|(15,[2],[1.0])|(14,[3],[1.0])|0.0  |\n",
      "|[2.3701360743042876]|[0.7391906807948887]|[0.0]                |[0.0]|[0.4575290698692395]|(8,[2],[1.0])|(15,[2],[1.0])|(14,[2],[1.0])|0.0  |\n",
      "|[1.8013034164712585]|[1.9133549417327194]|[0.0]                |[0.0]|[1.407781753443814] |(8,[0],[1.0])|(15,[0],[1.0])|(14,[8],[1.0])|0.0  |\n",
      "|[2.5123442387625445]|[2.082601046522753] |[0.0]                |[0.0]|[1.407781753443814] |(8,[0],[1.0])|(15,[6],[1.0])|(14,[8],[1.0])|0.0  |\n",
      "|[1.327276201610401] |[3.0025900432970136]|[0.0]                |[0.0]|[1.407781753443814] |(8,[0],[1.0])|(15,[2],[1.0])|(14,[4],[1.0])|0.0  |\n",
      "+--------------------+--------------------+---------------------+-----+--------------------+-------------+--------------+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean = df_ohe.withColumnRenamed('salaryClass_si', 'label')\n",
    "df_clean = df_clean.select(['a_sc', 'fw_sc', 'cg_sc', 'cl_sc', 'hpw_sc', 'wc_ohe', 'edN_ohe', 'oc_ohe', 'label'])\n",
    "df_clean.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------+-----+\n",
      "|features                                                                                                         |label|\n",
      "+-----------------------------------------------------------------------------------------------------------------+-----+\n",
      "|(42,[0,1,2,4,11,15,31],[1.8487061379573442,0.6877735810696858,0.19880196875001743,1.407781753443814,1.0,1.0,1.0])|0.0  |\n",
      "|(42,[0,1,4,7,15,30],[2.3701360743042876,0.7391906807948887,0.4575290698692395,1.0,1.0,1.0])                      |0.0  |\n",
      "|(42,[0,1,4,5,13,36],[1.8013034164712585,1.9133549417327194,1.407781753443814,1.0,1.0,1.0])                       |0.0  |\n",
      "|(42,[0,1,4,5,19,36],[2.5123442387625445,2.082601046522753,1.407781753443814,1.0,1.0,1.0])                        |0.0  |\n",
      "|(42,[0,1,4,5,15,32],[1.327276201610401,3.0025900432970136,1.407781753443814,1.0,1.0,1.0])                        |0.0  |\n",
      "+-----------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We will now assemble our features according to the classification task.\n",
    "\n",
    "final_assembler_classif = VectorAssembler(inputCols=['a_sc', 'fw_sc', 'cg_sc', 'cl_sc', 'hpw_sc', 'wc_ohe', 'edN_ohe', 'oc_ohe'], outputCol='features')\n",
    "final_df_classif = final_assembler_classif.transform(df_clean)\n",
    "final_df_classif = final_df_classif.select(['features', 'label'])\n",
    "final_df_classif.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing for regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['a', 'fw', 'cg', 'cl']:\n",
    "    assembler = VectorAssembler(inputCols=[col], outputCol=f'{col}_vec')\n",
    "    df_reg = assembler.transform(df_reg)\n",
    "\n",
    "    scaler = StandardScaler(inputCol=f'{col}_vec', outputCol=f'{col}_sc')\n",
    "    df_reg = scaler.fit(df_reg).transform(df_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------+-----+\n",
      "|features                                                       |label|\n",
      "+---------------------------------------------------------------+-----+\n",
      "|[1.8487061379573442,0.6877735810696858,0.19880196875001743,0.0]|40.0 |\n",
      "|[2.3701360743042876,0.7391906807948887,0.0,0.0]                |13.0 |\n",
      "|[1.8013034164712585,1.9133549417327194,0.0,0.0]                |40.0 |\n",
      "|[2.5123442387625445,2.082601046522753,0.0,0.0]                 |40.0 |\n",
      "|[1.327276201610401,3.0025900432970136,0.0,0.0]                 |40.0 |\n",
      "+---------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We will now assemble our features according to the regression task.\n",
    "\n",
    "df_reg = df_reg.withColumnRenamed('hpw', 'label')\n",
    "final_assembler_reg = VectorAssembler(inputCols=['a_sc', 'fw_sc', 'cg_sc', 'cl_sc'], outputCol='features')\n",
    "final_df_reg = final_assembler_reg.transform(df_reg)\n",
    "final_df_reg = final_df_reg.select(['features', 'label'])\n",
    "final_df_reg.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Splitting the data into training and testing.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the dataset is huge (10M rows), we will take a sample of it i.e. 30-70% of the data will be sampled first. Then we will split it into train-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df):\n",
    "    train, test = df.sample(fraction=0.3, seed=3).randomSplit([0.75, 0.25])\n",
    "    print(f\"Size of train dataset = {train.count()}\")\n",
    "    print(f\"Size of test dataset = {test.count()}\")\n",
    "    print()\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For classification task:\n",
      "Size of train dataset = 2249488\n",
      "Size of test dataset = 750256\n",
      "\n",
      "+------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|features                                                                                                          |label|\n",
      "+------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|(42,[0,1,2,3,4],[0.8532489867495435,2.564608629365143,0.3359698404726606,2.7479168024697795,3.4842598397734394])  |0.0  |\n",
      "|(42,[0,1,2,3,4],[0.9006517082356292,2.150654395080528,0.24095822799277644,2.3159475107984773,0.49272361370533485])|1.0  |\n",
      "|(42,[0,1,2,3,4],[0.948054429721715,1.9916828375694908,0.31191974029729047,2.6644834813370046,0.7390854205580023]) |0.0  |\n",
      "|(42,[0,1,2,3,4],[1.0428598726938865,2.5677939164749524,0.21297598216135724,2.4559001785050674,0.809474508230193]) |0.0  |\n",
      "|(42,[0,1,2,3,4],[1.1376653156660579,1.049272613701945,0.4286038765093522,3.011673753147584,0.3519454383609535])   |1.0  |\n",
      "+------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|features                                                                                                           |label|\n",
      "+-------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|(42,[0,1,2,3,4],[1.2798734801243152,0.42501844884153067,0.19880196875001743,3.7060542967687424,2.1468671740018164])|0.0  |\n",
      "|(42,[0,1,2,3,4],[1.2798734801243152,1.5191423893960903,0.2638195399465503,3.1650834081336536,0.8798635959023837])  |0.0  |\n",
      "|(42,[0,1,2,3,4],[1.6590952520130013,1.006142584061874,0.6188099919647507,2.1248582914298635,2.8859525945598183])   |0.0  |\n",
      "|(42,[0,1,2,3,4],[2.133122466873859,1.4192716604043931,1.3738734031739936,2.2217485998421185,2.8859525945598183])   |1.0  |\n",
      "|(42,[0,1,2,3,4],[2.3701360743042876,1.321663461253926,1.6899996248707785,2.145043772349083,0.10558363150828604])   |1.0  |\n",
      "+-------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('For classification task:')\n",
    "train_c, test_c = split(df=final_df_classif)\n",
    "train_c.show(5, truncate=False)\n",
    "test_c.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For regression task:\n",
      "Size of train dataset = 2249435\n",
      "Size of test dataset = 750309\n",
      "\n",
      "+------------------------------------------------------------------------------+-----+\n",
      "|features                                                                      |label|\n",
      "+------------------------------------------------------------------------------+-----+\n",
      "|[0.8058462652634577,0.1816146012554234,1.4476697181607756,2.2177115036582746] |74.0 |\n",
      "|[0.8058462652634577,0.18450709038577992,0.5956743442675315,4.9562084150324175]|47.0 |\n",
      "|[0.8058462652634577,0.185908971620738,0.26583133539848236,2.2217485998421185] |27.0 |\n",
      "|[0.8058462652634577,0.1918802758683759,0.34575448198887576,3.050699016258075] |41.0 |\n",
      "|[0.8058462652634577,0.19930669734723608,0.3359698404726606,2.8919065663602135]|19.0 |\n",
      "+------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------------------------------------------------------------------------+-----+\n",
      "|features                                                                       |label|\n",
      "+-------------------------------------------------------------------------------+-----+\n",
      "|[0.8058462652634577,0.17609580297603145,0.10726527568710692,2.9618829002135083]|22.0 |\n",
      "|[0.8058462652634577,0.20324616107078916,1.239083107894543,3.050699016258075]   |64.0 |\n",
      "|[0.8058462652634577,0.2106370918854732,0.4448811306204392,1.3107105610213345]  |46.0 |\n",
      "|[0.8058462652634577,0.21934117727467495,0.2374833085758028,2.116784099062176]  |5.0  |\n",
      "|[0.8058462652634577,0.22467364956714206,0.3750169612897063,3.3265672554874115] |7.0  |\n",
      "+-------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('For regression task:')\n",
    "train_r, test_r = split(df=final_df_reg)\n",
    "train_r.show(5, truncate=False)\n",
    "test_r.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Building a classification & a regression model and testing/reporting the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started.\n",
      "Training finished.\n",
      "\n",
      "Test metrics/results:\n",
      "accuracy = 50.01706%\n",
      "precision = 50.04921%\n",
      "recall = 46.89119%\n",
      "f1-score = 48.41876%\n",
      "\n",
      "Dataframe with predictions:\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(42,[0,1,2,3,4],[...|  0.0|[-0.0234825026104...|[0.49412964410142...|       1.0|\n",
      "|(42,[0,1,2,3,4],[...|  0.0|[-0.0162071483742...|[0.49594830159490...|       1.0|\n",
      "|(42,[0,1,2,3,4],[...|  0.0|[-0.0075972826771...|[0.49810068846618...|       1.0|\n",
      "|(42,[0,1,2,3,4],[...|  1.0|[-0.0109005243306...|[0.49727489590068...|       1.0|\n",
      "|(42,[0,1,2,3,4],[...|  1.0|[-0.0099282020832...|[0.49751796986679...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "print('Training started.')\n",
    "lr_model = lr.fit(train_c)\n",
    "print('Training finished.\\n')\n",
    "\n",
    "classif_pred_df = lr_model.transform(test_c)\n",
    "\n",
    "TP = classif_pred_df.filter(classif_pred_df['label'] == 1).filter(classif_pred_df['prediction'] == 1).count()\n",
    "TN = classif_pred_df.filter(classif_pred_df['label'] == 0).filter(classif_pred_df['prediction'] == 0).count()\n",
    "FP = classif_pred_df.filter(classif_pred_df['label'] == 0).filter(classif_pred_df['prediction'] == 1).count()\n",
    "FN = classif_pred_df.filter(classif_pred_df['label'] == 1).filter(classif_pred_df['prediction'] == 0).count()\n",
    "\n",
    "acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + TN)\n",
    "f1_Score = (2 * precision * recall)/(precision + recall)\n",
    "\n",
    "print(f'Test metrics/results:') \n",
    "print(f'accuracy = {acc*100:.5f}%')\n",
    "print(f'precision = {precision*100:.5f}%')\n",
    "print(f'recall = {recall*100:.5f}%')\n",
    "print(f'f1-score = {f1_Score*100:.5f}%')\n",
    "\n",
    "print('\\nDataframe with predictions:')\n",
    "classif_pred_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started.\n",
      "Training finished.\n",
      "\n",
      "Test metrics/results:\n",
      "MSE = 806.9079288324978\n",
      "\n",
      "Dataframe with predictions:\n",
      "+--------------------+-----+------------------+\n",
      "|            features|label|        prediction|\n",
      "+--------------------+-----+------------------+\n",
      "|[0.80584626526345...| 22.0|48.494436943028155|\n",
      "|[0.80584626526345...| 64.0| 48.50154758794418|\n",
      "|[0.80584626526345...| 46.0|  48.3794670792577|\n",
      "|[0.80584626526345...|  5.0| 48.43548907988203|\n",
      "|[0.80584626526345...|  7.0| 48.51998045463998|\n",
      "+--------------------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "\n",
    "print('Training started.')\n",
    "lin_reg_model = lin_reg.fit(train_r)\n",
    "print('Training finished.\\n')\n",
    "\n",
    "reg_preds_df = lin_reg_model.transform(test_r)\n",
    "\n",
    "reg_metrics = lin_reg_model.evaluate(test_r)\n",
    "\n",
    "print(f'Test metrics/results:') \n",
    "print(f'MSE = {reg_metrics.meanSquaredError}')\n",
    "\n",
    "print('\\nDataframe with predictions:')\n",
    "reg_preds_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Using the models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For using the models, we will take one random sample from the preprocessed test dataset and get predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(42,[0,1,2,3,4,5,...|  0.0|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_sample = test_c.sample(0.01).limit(1)\n",
    "random_sample.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(42,[0,1,2,3,4,5,...|  0.0|[0.04130605650358...|[0.51032504612650...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = lr_model.transform(random_sample)\n",
    "prediction.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the resulted df, the actual label and predicted label are the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[0.80584626526345...| 68.0|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_sample = test_r.sample(0.01).limit(1)\n",
    "random_sample.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----------------+\n",
      "|            features|label|       prediction|\n",
      "+--------------------+-----+-----------------+\n",
      "|[0.80584626526345...| 68.0|48.47679680848794|\n",
      "+--------------------+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = lin_reg_model.transform(random_sample)\n",
    "prediction.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the resulted df, the actual label is 68.0 and the predicted label is 48.48. The difference is acceptable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "  <p><b>THE END</b></p>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "faafacdf547457256517978ccd617e5232c831db2db3475f4239736a0901b48f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
